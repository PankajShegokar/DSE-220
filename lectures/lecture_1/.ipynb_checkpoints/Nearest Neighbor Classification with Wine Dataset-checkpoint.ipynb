{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This notebook discusses the nearest neighbor classification implementation.\n",
    "Outline:\n",
    "    Demonstrate working of a simple k-NN classifier in Scikit-learn\n",
    "    Load wine dataset\n",
    "    Perform k-NN using Scikit-learn on the wine dataset\n",
    "    Vary similarity measures to see performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset - 4 samples, two classes (0 and 1)\n",
    "# Use 1-D data\n",
    "X = [[0], [1], [2], [3]] # 4x1-dimensional\n",
    "y = [0, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have above are one dimensional points. Logically, a decision boundary should exist at x = 1.5. We will verify if it holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "print (neigh.predict([[1.1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print (neigh.predict([[1.6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "# Get probability\n",
    "print (neigh.predict_proba([[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's train a k-NN on Wine dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Description\n",
    "1. Multiclass classification problem with 3 classes: {1,2,3} representing 3 different cultivators\n",
    "2. 13 continuous attributes\n",
    "3. UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('wine_original.csv')\n",
    "labels = data['class']\n",
    "del data['class']\n",
    "X = data\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into testing and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.6944444444444444\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print ('accuracy = ' + str(np.sum(predictions == y_test)/(len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-4ed50b71ccec>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-4ed50b71ccec>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    By default 'Minkowski' distance with power 2 is used. Let us modify the distance measure to Manhattan distance\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#By default 'Minkowski' distance with power 2 is used. Let us modify the distance measure to Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter 'p' is the Power parameter for the Minkowski metric.\n",
    "# p = 1 --> Manhattan distance\n",
    "# p = 2 --> Euclidean distance\n",
    "\n",
    "clf = KNeighborsClassifier(3, p=1) # p = 1 corresponds to Manhattan distance\n",
    "# p = 2 gives Euclidean distance (default is p = 2 and hence, Euclidean distance)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy = np.sum(predictions == y_test)/(len(y_test))\n",
    "print (\"Accuracy = \" + str(accuracy) + \" at k = 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice question - Iris dataset"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
