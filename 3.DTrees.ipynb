{
 "metadata": {
  "name": "",
  "signature": "sha256:d6ad188e02315d1fcd66f6478261585aabc0953f273f95a775c2cadb8e8d7ca7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Loading Datasets with scikit-learn"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the intro portion of this tutorial, we'll be loading several dataset examples.  Scikit-learn has methods to access several datasets: we'll explore two of these here."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading Iris Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The machine learning community often uses a simple flowers database where each row in the database (or CSV file) is a set of measurements of an individual iris flower. Each sample in this dataset is described by 4 features and can belong to one of the target classes:\n",
      "\n",
      "- Features in the Iris dataset:\n",
      "\n",
      "  1. sepal length in cm\n",
      "  2. sepal width in cm\n",
      "  3. petal length in cm\n",
      "  4. petal width in cm\n",
      "\n",
      "- Target classes to predict:\n",
      "\n",
      "  1. Iris Setosa\n",
      "  2. Iris Versicolour\n",
      "  3. Iris Virginica"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "``scikit-learn`` embeds a copy of the iris CSV file along with a helper function to load it into numpy arrays:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_iris\n",
      "iris = load_iris()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The features of each sample flower are stored in the ``data`` attribute of the dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples, n_features = iris.data.shape\n",
      "print n_samples\n",
      "print n_features\n",
      "print iris.data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "150\n",
        "4\n",
        "[ 5.1  3.5  1.4  0.2]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The information about the class of each sample is stored in the ``target`` attribute of the dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(iris.data) == len(iris.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The names of the classes are stored in the last attribute, namely ``target_names``:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(iris.target_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "['setosa', 'versicolor', 'virginica']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data downloaded from the iris dataset is stored locally, within a subdirectory of your home directory.  You can use the following to determine where it is:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import get_data_home\n",
      "get_data_home()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "'C:\\\\Users\\\\nbalac\\\\scikit_learn_data'"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take a moment now to examine this directory and see that the iris data is stored there.  You may also be curious about other datasets which are available.  These can be found in ``sklearn.datasets``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can see which datasets are available by using ipython's tab-completion feature.  Simply type\n",
      "\n",
      "   ``datasets.fetch_``\n",
      "\n",
      "or\n",
      "\n",
      "   ``datasets.load_``\n",
      "\n",
      "and then press the tab key.  This will give you a drop-down menu which lists all the datasets that can be fetched."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datasets.fetch_mldata\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<function sklearn.datasets.mldata.fetch_mldata>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Be warned: many of these datasets are quite large!  If you start a download and you want to kill it, you can use ipython's \"kernel interrupt\" feature, available in the menu or using the shortcut ``Ctrl-m i``.\n",
      "\n",
      "(You can press ``Ctrl-m h`` for a list of all ``ipython`` keyboard shortcuts)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Simple Decision Tree Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Decision Tree Classifier\n",
      "from sklearn import datasets\n",
      "from sklearn import metrics\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "# load the iris datasets\n",
      "dataset = datasets.load_iris()\n",
      "# fit a CART model to the data\n",
      "model = DecisionTreeClassifier()\n",
      "model.fit(dataset.data, dataset.target)\n",
      "print(model)\n",
      "# make predictions\n",
      "expected = dataset.target\n",
      "predicted = model.predict(dataset.data)\n",
      "# summarize the fit of the model\n",
      "print(metrics.classification_report(expected, predicted))\n",
      "print(metrics.confusion_matrix(expected, predicted))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            random_state=None, splitter='best')\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       1.00      1.00      1.00        50\n",
        "          1       1.00      1.00      1.00        50\n",
        "          2       1.00      1.00      1.00        50\n",
        "\n",
        "avg / total       1.00      1.00      1.00       150\n",
        "\n",
        "[[50  0  0]\n",
        " [ 0 50  0]\n",
        " [ 0  0 50]]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "A more involved Decision Tree Classifier version"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print __doc__\n",
      "\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "# Parameters\n",
      "n_classes = 3\n",
      "plot_colors = \"bry\"\n",
      "plot_step = 0.02\n",
      "\n",
      "# Load data\n",
      "iris = load_iris()\n",
      "\n",
      "for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3],\n",
      "                                [1, 2], [1, 3], [2, 3]]):\n",
      "     # We only take the two corresponding features\n",
      "    X = iris.data[:, pair]\n",
      "    y = iris.target\n",
      "\n",
      "    # Shuffle\n",
      "    idx = np.arange(X.shape[0])\n",
      "    np.random.seed(13)\n",
      "    np.random.shuffle(idx)\n",
      "    X = X[idx]\n",
      "    y = y[idx]\n",
      "\n",
      "    # Standardize\n",
      "    mean = X.mean(axis=0)\n",
      "    std = X.std(axis=0)\n",
      "    X = (X - mean) / std\n",
      "\n",
      "    # Train\n",
      "    clf = DecisionTreeClassifier().fit(X, y)\n",
      "\n",
      "    # Plot the decision boundary\n",
      "    pl.subplot(2, 3, pairidx + 1)\n",
      "\n",
      "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
      "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
      "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
      "                         np.arange(y_min, y_max, plot_step))\n",
      "\n",
      "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
      "    Z = Z.reshape(xx.shape)\n",
      "    cs = pl.contourf(xx, yy, Z, cmap=pl.cm.Paired)\n",
      "\n",
      "    pl.xlabel(iris.feature_names[pair[0]])\n",
      "    pl.ylabel(iris.feature_names[pair[1]])\n",
      "    pl.axis(\"tight\")\n",
      "\n",
      "    # Plot the training points\n",
      "    for i, color in zip(xrange(n_classes), plot_colors):\n",
      "        idx = np.where(y == i)\n",
      "        pl.scatter(X[idx, 0], X[idx, 1], c=color, label=iris.target_names[i],\n",
      "                cmap=pl.cm.Paired)\n",
      "\n",
      "    pl.axis(\"tight\")\n",
      "\n",
      "pl.suptitle(\"Decision surface of a decision tree using paired features\")\n",
      "pl.legend()\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}